<!DOCTYPE html>
<html lang="en">
<head>
<title>ICDAR 2023 Competition on Language Guided Document Editing (DocEdit)</title>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
<link href="layout/styles/layout.css" rel="stylesheet" type="text/css" media="all">
</head>
<body id="top">
<div class="wrapper row1">
  <header id="header" class="hoc clear"> 
    <!-- ################################################################################################ -->
    <div id="logo" class="fl_left">
      <h1><a href="index.html">DocEdit@ICDAR 2023</a></h1>
    </div>
    <nav id="mainav" class="fl_right">
      <ul class="clear">
        <li class="active"><a href="index.html">Home</a></li>
        <li><a href="schedule.html">Schedule</a></li>
        <li><a href="talks.html">Invited Talks</a></li>
        <li><a href="tutorial.html">Invited Tutorials</a></li>
        <li><a href="cfp.html">CFP</a></li>
        <li><a href="shared_task.html">Shared Tasks</a></li>
        <li><a href="index.html#important-date">Important Dates</a></li>
        <li><a href="index.html#organizer">Organizers</a></li>
      </ul>
    </nav>
    <!-- ################################################################################################ -->
  </header>
</div>
<!-- ################################################################################################ -->
<!-- ################################################################################################ -->
<!-- ################################################################################################ -->
<div class="wrapper bgded overlay" style="background-image:url('images/demo/backgrounds/muffin.jpeg');">
  <div id="pageintro" class="hoc clear"> 
    <!-- ################################################################################################ -->
      <h3 class="heading">ICDAR 2023 Competition on Language Guided Document Editing (DocEdit)</h3>
      <h4>August 21-26, 2023</h4>
      <h4>Location: San José, California, USA</h4>
    <!-- ################################################################################################ -->
  </div>
</div>
<!-- ################################################################################################ -->
<div class="wrapper row3"  style="background-color: whitesmoke;">
  <main class="hoc container clear">
    <!-- main body -->
    <!-- ################################################################################################ -->
    <section>
      <div>
        <h6 class="heading">News</h6>
        <ul>
          <li><strong>August 21-26, 2023</strong>: DocEdit Competition at ICDAR 2023</li>
          <li><strong>Mar 15, 2023</strong>: DocEdit is open for submission</li>
          <li><strong>Mar 10, 2023</strong>: DocEdit website is launched</li>
        </ul>
      </div>
    </section>
  </main>
</div>

<div class="wrapper row3"  style="background-color: lightgray;">
  <main class="hoc container clear">
    <section>
      <div>
        <h6 class="heading">About the competition</h6>
        <p>
          Billions of digital documents and PDF's are created, edited or shared each year ubiquitously, with a majority of them being designed by amateur users. Professional document editing requires a certain level of expertise to perform complex edit operations. To make editing tools accessible to increasingly novice users, there is a need for intelligent document assistant systems that can make or suggest edits based on a user’s natural language request. Such a system should be able to understand the user’s ambiguous requests and contextualize them to the visual cues and textual content found in a document image to edit the text and its structured layout. Unparalleled advances in deep learning, language/foundation models, and generative AI has made it possible to utilize multimodal cues for automated document manipulation. However, there are several unresolved challenges towards realizing this goal: (1) extracting intent, sequence of actions, and visual attributes of the document, (2) document hierarchical parsing for layout understanding, (3) understanding direct and indirect references to document objects, (4) inferring local and global relations between embedded text and visual objects through multimodal (text+visual+layout) signals, and (5) grounding the requested edits to localized objects and scene text. To address all these major challenges, it is critical that we develop more reliable and accurate AI techniques for automated document editing  that can handle the inherent complexity of the task. To this end, we propose the first "ICDAR 2023 Competition on Language-Guided Document Editing (DocEdit)". The main goal of this competition is to bring together researchers from various domains such as natural language processing, computer vision, machine learning, human computer interaction, data mining, graphics, and multimedia to explore artificial intelligence solutions for language-guided document editing.
 
        </p>
        <p>
          This competition will be of interest to researchers working in natural language processing, computer vision, multimodal deep learning, document intelligence, signal processing, artificial intelligence, information extraction and retrieval, and data mining and in particular to those who are interested in the applications of AI in document understanding. ICDAR 2023 will be sought after destination for researchers from document analysis and representation, computer vision and language communities. With the rise of Transformer and Stable Diffusion based techniques in AI, the competition will be of very high interest to researchers in generative AI and vision+language modeling. The competition aims to attract young researchers from universities, early-career AI practitioners as well as industry veterans in the document intelligence space.
        </p>

      </div>
    </section>
  </main>
</div>

<div class="wrapper row3"  style="background-color: whitesmoke;">
  <main class="hoc container clear">
    <section>
      <div>
        <h6 id="important-date" class="heading">Important dates</h6>
        <ul>
          <li>DocEdit is accepted at ICDAR 2023: January 2023</li>
          <li>DocEdit website is launched: March 10, 2023</li>
          <li>DocEdit is open for submission: March 15, 2023</li>
          <li>Submission deadline: April 10, 2023</li>
          <li>Winners Announced: April 12, 2023</li>
          <li><strong>DocEdit competition at ICDAR 2023:</strong> Aug 21-26, 2023</li>
        </ul>
        <p>All deadlines are end of day, anywhere on earth (UTC-12).</p>
      </div>
    </section>
  </main>
</div>


<div class="wrapper row3"  style="background-color: lightgray;">
  <main class="hoc container clear">
    <section>
      <div>
        <h6 id="organizer" class="heading">Organizers</h6>
        <ul>
          <li><a href="http://www.cs.umd.edu/~puneetm/">Puneet Mathur</a>, University of Maryland College Park, USA</li>
          <li><a href="https://research.adobe.com/person/rajiv-jain/">Rajiv Jain</a>, Adobe Research, USA</li>
          <li><a href="https://research.adobe.com/person/jiuxiang-gu/">Jiuxiang Gu</a>, Adobe Research, USA</li>
          <li><a href="https://research.adobe.com/person/franck-dernoncourt/">Franck Dernoncourt</a>, Adobe Research, USA</li>
          <li><a href="https://research.adobe.com/person/vlad-morariu/">Vlad Morariu</a>, Adobe Research, USA</li>
          <li><a href="https://www.cs.umd.edu/people/dmanocha">Dinesh Manocha</a>, University of Maryland College Park, USA</li>
        </ul>
      </div>
    </section>
  </main>
</div>


<!-- <div class="wrapper row3"  style="background-color: lightgray;">
  <main class="hoc container clear">
    <section>
      <div>
        <h6 id="organizer" class="heading">Program Committee</h6>
        <ul>
          
          <li>Miguel Villarreal-Vasquez, JP Morgan AI</li>
          <li>Yao Xuan, Meta</li>       
          <li>Mihir Goyal, Sharechat</li>
          <li>Sreyan Ghosh, University of Maryland College Park</li>
          <li>Shishira Maiya, University of Maryland College Park</li>
          <li>Yow-Ting Shiue, University of Maryland College Park</li>
          <li>Apoorv Singh, Motional</li>
          <li>Vineet Malhotra, MIDAS IIIT Delhi</li>
          
        </ul>
      </div>
    </section>
  </main>
</div> -->
  
<div class="wrapper row3"  style="background-color: midnightblue;">
  <main class="hoc container clear">
    <div class="clear">
      <p style="color: antiquewhite;">Contact us: docedit.icdar2023@gmail.com or puneetm@umd.edu</p>
    </div>
  </main>
</div>


<a id="backtotop" href="#top"><i class="fa fa-chevron-up"></i></a>
<!-- JAVASCRIPTS -->
<script src="layout/scripts/jquery.min.js"></script>
<script src="layout/scripts/jquery.backtotop.js"></script>
<script src="layout/scripts/jquery.mobilemenu.js"></script>
</body>
</html>
